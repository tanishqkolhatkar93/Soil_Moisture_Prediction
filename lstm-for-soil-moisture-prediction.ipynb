{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-09-30T07:23:38.77918Z","iopub.status.busy":"2023-09-30T07:23:38.778847Z","iopub.status.idle":"2023-09-30T07:23:38.786372Z","shell.execute_reply":"2023-09-30T07:23:38.785165Z","shell.execute_reply.started":"2023-09-30T07:23:38.779155Z"}},"source":["<h2>ðŸ“– Table of Contents</h2>\n","\n","<ol style=\"border: 2px solid #e8e8e8; padding: 15px; border-radius: 8px; background-color: #f9f9f9;\">\n","    <li><a href=\"#intro_notebook\" style=\"text-decoration: none; color: #333;\"><strong>Introduction to the Notebook</strong></a></li>\n","    <li><a href=\"#intro_dataset\" style=\"text-decoration: none; color: #333;\"><strong>Introduction to the Dataset</strong></a></li>\n","    <li><a href=\"#eda\" style=\"text-decoration: none; color: #333;\"><strong>Exploratory Data Analysis (EDA)</strong></a></li>\n","    <li><a href=\"#intro_lstm\" style=\"text-decoration: none; color: #333;\"><strong>Introduction to LSTM</strong></a></li>\n","    <li><a href=\"#lstm_input\" style=\"text-decoration: none; color: #333;\"><strong>LSTM Input Sequencing</strong></a></li>\n","    <li><a href=\"#data_missing\" style=\"text-decoration: none; color: #333;\"><strong>Handling Incomplete Sequences in Time-Series Forecasting</strong></a></li>\n","    <li><a href=\"#lstm_model\" style=\"text-decoration: none; color: #333;\"><strong>LSTM Model Predictions</strong></a></li>\n","    <li><a href=\"#conclu\" style=\"text-decoration: none; color: #333;\"><strong>Conclusions</strong></a></li>\n","</ol>\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-30T07:14:09.657238Z","iopub.status.busy":"2023-09-30T07:14:09.656807Z","iopub.status.idle":"2023-09-30T07:14:09.667496Z","shell.execute_reply":"2023-09-30T07:14:09.665833Z","shell.execute_reply.started":"2023-09-30T07:14:09.657191Z"}},"source":["<a id=\"intro_notebook\"></a>\n","<h2 style=\"font-family: 'Georgia'; color: #34495e; border-bottom: 3px solid #3498db; padding-bottom: 10px;\">From Earth to AI: Time Series Prediction of Soil Moisture with LSTM</h2>\n","<p style=\"font-family: 'Arial'; font-size: 16px; color: #2c3e50; margin-top: 20px;\"> I recently acquired a dataset on soil moisture in Germany for the year 2013 from a colleague at Forschungszentrum Julich. The colleague inquired if it's feasible to deploy LSTM on this dataset. Since it's open-source, I decided to give it a shot. I've been meaning to create a beginner friendly notebook on LSTM for a while now. In this notebook, I'll try to explore into the dataset, conduct a thorough exploratory data analysis, and try using the LSTM technique. I hope this will be helpful for others.</p>\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"intro_dataset\"></a>\n","<h2 style=\"font-family: 'Georgia'; color: #34495e; border-bottom: 3px solid #3498db; padding-bottom: 10px;\">Exploring the dataset</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:33.315084Z","iopub.status.busy":"2023-10-04T11:25:33.314652Z","iopub.status.idle":"2023-10-04T11:25:33.326072Z","shell.execute_reply":"2023-10-04T11:25:33.324905Z","shell.execute_reply.started":"2023-10-04T11:25:33.314987Z"},"trusted":true},"outputs":[],"source":["# all necessary libraries imported here\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import folium\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.layers import Dropout\n","from keras.regularizers import L1L2\n","from keras.callbacks import EarlyStopping"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:33.329136Z","iopub.status.busy":"2023-10-04T11:25:33.328426Z","iopub.status.idle":"2023-10-04T11:25:33.760186Z","shell.execute_reply":"2023-10-04T11:25:33.758883Z","shell.execute_reply.started":"2023-10-04T11:25:33.329104Z"},"trusted":true},"outputs":[],"source":["# Load the data\n","df = pd.read_csv('/kaggle/input/soil-moisture-remote-sensing-data-germany-2013/updated_data.csv')\n","\n","# Data overview\n","print(\"Dataset Shape:\", df.shape)\n","print(\"\\nFirst 5 rows of the dataset:\")\n","print(df.head())\n","\n","# Check for missing values\n","print(\"\\nMissing values in each column:\")\n","print(df.isnull().sum())\n","\n","# Descriptive statistics\n","print(\"\\nDescriptive statistics of the dataset:\")\n","print(df.describe())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:33.762037Z","iopub.status.busy":"2023-10-04T11:25:33.76149Z","iopub.status.idle":"2023-10-04T11:25:33.792102Z","shell.execute_reply":"2023-10-04T11:25:33.790872Z","shell.execute_reply.started":"2023-10-04T11:25:33.762008Z"},"trusted":true},"outputs":[],"source":["# Determine unique latitude-longitude pairs\n","unique_locations = df[['latitude', 'longitude']].drop_duplicates().reset_index(drop=True)\n","print(f\"There are {unique_locations.shape[0]} unique locations in the dataset.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:33.794809Z","iopub.status.busy":"2023-10-04T11:25:33.794494Z","iopub.status.idle":"2023-10-04T11:25:34.970168Z","shell.execute_reply":"2023-10-04T11:25:34.969157Z","shell.execute_reply.started":"2023-10-04T11:25:33.794783Z"},"trusted":true},"outputs":[],"source":["# Create a base map centered around Germany\n","m = folium.Map(location=[51.1657, 10.4515], zoom_start=5, tiles=\"OpenStreetMap\", width=800, height=800)\n","\n","# Add unique locations to the map\n","for idx, row in unique_locations.iterrows():\n","    folium.CircleMarker(\n","        location=(row['latitude'], row['longitude']),\n","        radius=2,\n","        color='blue',\n","        fill=True,\n","        fill_color='blue',\n","        fill_opacity=0.6\n","    ).add_to(m)\n","\n","# Display the map directly\n","m"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border: 2px dashed #3498db; padding: 15px; border-radius: 8px; background-color: #f9f9f9; font-family: 'Georgia';\">\n","    <h3 style=\"color: #e74c3c; border-bottom: 1px solid #3498db; padding-bottom: 10px;\">Surprise Revelation!</h3>\n","    <p style=\"color: #34495e; font-size: 16px;\">Oh, I thought dataset only encompasses Germany, but I think it goes beyond Germany into Denmark, France, Belgium, and other neighboring European countries. So really, the dataset encompasses many countries in Europe. I didn't know this prior to this plot.</p>\n","</div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:34.971832Z","iopub.status.busy":"2023-10-04T11:25:34.971442Z","iopub.status.idle":"2023-10-04T11:25:35.064341Z","shell.execute_reply":"2023-10-04T11:25:35.063251Z","shell.execute_reply.started":"2023-10-04T11:25:34.971806Z"},"trusted":true},"outputs":[],"source":["# Create a unique identifier for each location\n","df['location_id'] = df.groupby(['latitude', 'longitude']).ngroup()\n","# Determine the start and end of the time series\n","start_date = df['time'].min()\n","end_date = df['time'].max()\n","print(f\"The time series starts on {start_date} and ends on {end_date}.\")"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"eda\"></a>\n","<h2 style=\"font-family: 'Georgia'; color: #34495e; border-bottom: 3px solid #3498db; padding-bottom: 10px;\">Exploratory Data Analysis</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:35.065817Z","iopub.status.busy":"2023-10-04T11:25:35.065526Z","iopub.status.idle":"2023-10-04T11:25:35.809654Z","shell.execute_reply":"2023-10-04T11:25:35.808364Z","shell.execute_reply.started":"2023-10-04T11:25:35.065794Z"},"trusted":true},"outputs":[],"source":["# Randomly select five unique location IDs\n","random_locations = np.random.choice(df['location_id'].unique(), 5, replace=False)\n","\n","# Plot time series data for the selected locations\n","plt.figure(figsize=(10, 5))\n","for location in random_locations:\n","    subset = df[df['location_id'] == location]\n","    lat = subset['latitude'].iloc[0]\n","    lon = subset['longitude'].iloc[0]\n","    plt.plot(pd.to_datetime(subset['time']), subset['sm_tgt'], label=f\"Location {location} (Lat: {lat:.2f}, Lon: {lon:.2f})\")\n","\n","plt.title(\"Soil Moisture Time Series for Randomly Selected Locations\")\n","plt.xlabel(\"Time\")\n","plt.ylabel(\"Soil Moisture Value\")\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:35.812092Z","iopub.status.busy":"2023-10-04T11:25:35.811428Z","iopub.status.idle":"2023-10-04T11:25:37.879842Z","shell.execute_reply":"2023-10-04T11:25:37.878552Z","shell.execute_reply.started":"2023-10-04T11:25:35.812052Z"},"trusted":true},"outputs":[],"source":["# Set style and context to make the plot look fancy\n","sns.set_style(\"whitegrid\")\n","sns.set_context(\"talk\")\n","\n","# Create the distribution plot\n","plt.figure(figsize=(12, 8))\n","sns.histplot(df['sm_tgt'], kde=True, bins=30, color='skyblue', edgecolor='black', linewidth=1.2)\n","\n","# Mark percentiles on the plot\n","percentiles = [5, 25, 50, 75, 95]\n","for percentile in percentiles:\n","    value = np.percentile(df['sm_tgt'], percentile)\n","    plt.axvline(value, color='red', linestyle='dashed', linewidth=1)\n","    plt.text(value, 5, f'{percentile}%', color='red', rotation=90, verticalalignment='bottom')\n","\n","# Set the title and labels\n","plt.title(\"Distribution of Soil Moisture for the Year 2013\", fontsize=18)\n","plt.xlabel(\"Soil Moisture Value\", fontsize=14)\n","plt.ylabel(\"Frequency\", fontsize=14)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border: 2px solid #3498db; padding: 15px; border-radius: 8px; background-color: #f9f9f9; font-family: 'Georgia';\">\n","    <h3 style=\"color: #e74c3c; border-bottom: 1px solid #3498db; padding-bottom: 10px;\">What we see in Histogram</h3>\n","    <ul style=\"color: #34495e; font-size: 16px;\">\n","        <li>Less than <strong style=\"color: #e74c3c;\">5%</strong> of soil moisture values indicate very dry conditions.</li>\n","        <li>Below <strong style=\"color: #e74c3c;\">20%</strong> of the data points show soil moisture values that can be categorized as somewhat low, with a threshold of <strong>0.25</strong> differentiating between sufficiently irrigated and not sufficiently irrigated regions.</li>\n","        <li>A significant proportion, more than <strong style=\"color: #e74c3c;\">50%</strong>, of the land has soil moisture values below <strong>40%</strong>, highlighting potential areas of concern.</li>\n","    </ul>\n","    <p style=\"color: #34495e; font-size: 16px; text-align: center;\"><em>These observations shed light on the distribution and potential challenges related to soil moisture in the studied regions for the year 2013.</em></p>\n","</div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:37.881755Z","iopub.status.busy":"2023-10-04T11:25:37.881376Z","iopub.status.idle":"2023-10-04T11:25:39.505034Z","shell.execute_reply":"2023-10-04T11:25:39.504Z","shell.execute_reply.started":"2023-10-04T11:25:37.88172Z"},"trusted":true},"outputs":[],"source":["# Randomly sample 2000 data points from the dataframe\n","sample_df = df.sample(n=2000, random_state=42)\n","\n","# Set the aesthetic style of the plots\n","sns.set_style(\"whitegrid\")\n","sns.set_context(\"talk\")\n","\n","# Initialize a figure with three subplots side by side\n","fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 6))\n","\n","# List of soil components\n","components = ['clay_content', 'sand_content', 'silt_content']\n","\n","# Plot scatter plots for each component\n","for i, component in enumerate(components):\n","    sns.regplot(x=component, y='sm_tgt', data=sample_df, ax=axes[i], color='skyblue', scatter_kws={'s':10}, line_kws={'color':'red'})\n","    \n","    # Calculate correlation and annotate the plot with its value\n","    correlation = sample_df[component].corr(sample_df['sm_tgt'])\n","    axes[i].set_title(f\"Correlation between {component.split('_')[0].capitalize()} and Soil Moisture: {correlation:.2f}\", fontsize=14)\n","\n","# Adjust layout for better display\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"border: 2px solid #2ecc71; padding: 15px; border-radius: 8px; background-color: #f9f9f9; font-family: 'Georgia';\">\n","    <h3 style=\"color: #e67e22; border-bottom: 1px solid #2ecc71; padding-bottom: 10px;\">Soil Composition vs. Soil Moisture: Observations</h3>\n","    <ul style=\"color: #34495e; font-size: 16px;\">\n","        <li>The correlation plots do not indicate any <strong style=\"color: #e74c3c;\">strong relationships</strong> between soil composition and soil moisture.</li>\n","        <li>There are very weak trends (red lines) observed (not to be considered seriously):\n","            <ul>\n","                <li>Higher clay content is associated with <strong style=\"color: #3498db;\">lower soil moisture</strong>.</li>\n","                <li>Higher sand content seems to correspond with <strong style=\"color: #3498db;\">greater soil moisture</strong>.</li>\n","                <li>Increased silt content is related to <strong style=\"color: #3498db;\">reduced soil moisture</strong>.</li>\n","            </ul>\n","        </li>\n","        <li>The data appears scattered without a clear directional trend, suggesting that soil moisture may not be predominantly influenced by soil type alone.</li>\n","        <li>Given the dataset's origin from Europe, where many agricultural areas benefit from <strong style=\"color: #3498db;\">automated irrigation systems</strong>, the lack of a clear trend may hint at the impact of artificial irrigation.</li>\n","        <li>It's crucial to note that the plots were generated using a <strong style=\"color: #e67e22;\">random sample of 2000 data points</strong> from the extensive dataset to conserve computational resources that Kaggle genourously gives us!</li>\n","    </ul>\n","    <p style=\"color: #34495e; font-size: 16px; text-align: center;\"><em>In summary, the data suggests that while there are weak trends between soil type and moisture, other factors, possibly artificial irrigation, play a significant role in determining soil moisture levels.</em></p>\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"intro_lstm\"></a>\n","<h2 style=\"font-family: 'Georgia'; color: #34495e; border-bottom: 3px solid #3498db; padding-bottom: 10px;\">Introduction to LSTM</h2>"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"color: #2ecc71; border-bottom: 2px solid #e67e22; padding-bottom: 10px;\">The Bike Ride from Point A to Point B: RNN vs. LSTM</h2>\n","\n","<p style=\"color: #34495e; font-size: 18px;\">Imagine you took a bike ride from Point A to Point B, a journey filled with various experiences.</p>\n","\n","<h4 style=\"color: #3498db;\">Major Events:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>Starting at Point A, you felt the morning chill.</li>\n","    <li>Midway, you stopped at a cafe and had a memorable conversation with a stranger.</li>\n","    <li>You crossed a beautiful bridge with a river flowing beneath.</li>\n","    <li>Finally, you reached Point B just in time to witness a breathtaking sunset.</li>\n","</ul>\n","\n","<h4 style=\"color: #3498db;\">Minor Details:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>The song playing in the cafe.</li>\n","    <li>A bird you saw while crossing the bridge.</li>\n","    <li>The brand of a passing bike.</li>\n","</ul>\n","\n","<div style=\"text-align:center;\">\n","    <img src=\"https://github.com/sraocodes/images/blob/main/lstm_bike.png?raw=true\" alt=\"Illustration\" style=\"width:300px; border: 1px solid #e67e22; padding: 5px; border-radius: 8px;\">\n","</div>\n","\n","\n","<p style=\"color: #34495e; font-size: 18px;\">Now, let's relate this to neural networks:</p>\n","\n","<h4 style=\"color: #e74c3c;\">Recurrent Neural Networks (RNNs):</h4>\n","<p style=\"color: #34495e; font-size: 16px;\">RNNs are like a quick journal entry. They'll note down the major events: starting at Point A, the cafe stop, crossing the bridge, and arriving at Point B. However, as the journey progresses, the earlier details, like the morning chill, might get overshadowed by the sunset at Point B.</p>\n","\n","<h4 style=\"color: #e74c3c;\">Long Short-Term Memory (LSTM):</h4>\n","<p style=\"color: #34495e; font-size: 16px;\">LSTMs are like a detailed travel diary. They'll remember the major events and also some of the minor details.\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>The Forget Gate might decide that the song in the cafe, while nice, isn't as crucial to the journey's narrative.</li>\n","    <li>The Input Gate might choose to remember the bird on the bridge because it added to the beauty of that moment.</li>\n","    <li>The Output Gate will use these memories to provide a comprehensive recount of the journey, ensuring both the sunrise at Point A and the sunset at Point B are given importance.</li>\n","</ul>\n","</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"color: #e67e22; border-bottom: 2px solid #3498db; padding-bottom: 10px;\">The Motorcycle Ride of Understanding LSTM</h2>\n","\n","<div style=\"text-align:center;\">\n","    <img src=\"https://github.com/sraocodes/images/blob/main/lstm.jpg?raw=true\" alt=\"Illustration\" style=\"width:900px; border: 1px solid #e67e22; padding: 5px; border-radius: 8px;\">\n","</div>\n","\n","<h4 style=\"color: #3498db;\">The Context:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>The previous hidden state, \\( h_{t-1} \\), and cell state, \\( c_{t-1} \\), set the context, like recalling the last landmark on your journey.</li>\n","</ul>\n","\n","<h4 style=\"color: #3498db;\">Forget Gate:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>As you continue, the forget gate determines which memories to keep and which to discard.</li>\n","</ul>\n","\n","<h4 style=\"color: #3498db;\">Input Gate:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>This gate decides new experiences to store, like noting an important point on your route.</li>\n","</ul>\n","\n","<h4 style=\"color: #3498db;\">Memory Update:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>The gates work together to update your long-term memory or the cell state.</li>\n","</ul>\n","\n","<h4 style=\"color: #3498db;\">Output Gate:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>The output gate uses the long-term memory to create the current hidden state, \\( h_t \\), which represents your current thoughts.</li>\n","</ul>\n","\n","<h4 style=\"color: #3498db;\">Regulation:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>The sigmoid and tanh functions help regulate the memories and thoughts, keeping them balanced. Acting as our motorcycle's brakes and throttle, ensuring the memories and thoughts are balanced, preventing a skid or a burnout. Technically known as ðŸ’¥ðŸ’¥gradient explosionðŸ’¥ðŸ’¥ or vanising problem.</li>\n","</ul>\n","\n","<p style=\"color: #34495e; font-size: 18px; text-align: center;\"><em>Like the processes in a motorcycle ride, the LSTM cell effectively handles data. As we prepare to use LSTM on our soil moisture data, we need to set up our input sequences for the model to work efficiently.</em></p>\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"lstm_input\"></a>\n","<h2 style=\"font-family: 'Georgia'; color: #34495e; border-bottom: 3px solid #3498db; padding-bottom: 10px;\">Input Sequencing</h2>\n","\n","<h2 style=\"color: #e67e22; border-bottom: 2px solid #3498db; padding-bottom: 10px;\">Crafting Input Sequences for LSTM Modeling</h2>\n","\n","<p style=\"color: #34495e; font-size: 18px;\">When working with agricultural/hydrological data, gaps and missing values can pose challenge to train ML models. To tackle this, we've adopted a strategy for preparing our LSTM model.</p>\n","\n","<div style=\"text-align:center;\">\n","    <img src=\"https://github.com/sraocodes/images/blob/main/missingdata.jpg?raw=true\" alt=\"Illustration\" style=\"width:800px; border: 1px solid #e67e22; padding: 5px; border-radius: 8px;\">\n","</div>\n","\n","<h4 style=\"color: #3498db;\">Steps for Input Sequencing:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li><strong>June Data Extraction:</strong> Instead of using the typical last-month split for testing, we've taken out June's data, simulating real-world data gaps.</li>\n","    <li><strong>Choosing a Sequence Length:</strong> We will decide a sequence length, meaning our model will use data from say 30 preceding days to predict the next day's soil moisture.</li>\n","    <li><strong>Data Normalization:</strong> Essential for LSTM models to yield optimal results. Columns like latitude, longitude, and soil components should be normalized using the MinMaxScaler.</li>\n","    <li><strong>Sequence Creation:</strong> After sorting and grouping, sequences should be generated for each location. Each 30-day sequence of data will be paired with the correct subsequent day's soil moisture target.</li>\n","</ul>\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"color: #e67e22; border-bottom: 2px solid #3498db; padding-bottom: 10px;\">Remove June Data to Simulate Data Gap</h2>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:39.506808Z","iopub.status.busy":"2023-10-04T11:25:39.506442Z","iopub.status.idle":"2023-10-04T11:25:39.646656Z","shell.execute_reply":"2023-10-04T11:25:39.645559Z","shell.execute_reply.started":"2023-10-04T11:25:39.506777Z"},"trusted":true},"outputs":[],"source":["# Convert the 'time' column to datetime format\n","df['time'] = pd.to_datetime(df['time'])\n","\n","# Separate the data for June\n","june_data = df[df['time'].dt.month == 6]\n","\n","# Remove June data from the main dataframe\n","df = df[df['time'].dt.month != 6]\n","\n","june_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"color: #e67e22; border-bottom: 2px solid #3498db; padding-bottom: 10px;\">Create Input Sequencing</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["<p style=\"color: #34495e; font-size: 18px;\"> LSTM use gradient descent to update the network weights during training. Features that have a larger scale can dominate the cost function and make the optimization process more challenging, leading to longer training times and a model that might not converge. Hence in the next step we use MinMaxScaler to scale our data</p>\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:39.652028Z","iopub.status.busy":"2023-10-04T11:25:39.650852Z","iopub.status.idle":"2023-10-04T11:25:39.739419Z","shell.execute_reply":"2023-10-04T11:25:39.738349Z","shell.execute_reply.started":"2023-10-04T11:25:39.651988Z"},"trusted":true},"outputs":[],"source":["# Features to normalize\n","features_to_normalize = ['latitude', 'longitude', 'clay_content', 'sand_content', 'silt_content', 'sm_aux', 'location_id','sm_tgt']\n","\n","# Initialize scaler\n","scaler = MinMaxScaler()\n","\n","# Apply normalization to the dataframe (both training and June data)\n","df[features_to_normalize] = scaler.fit_transform(df[features_to_normalize])\n","june_data[features_to_normalize] = scaler.transform(june_data[features_to_normalize])\n","\n","# Reorder the columns to ensure 'sm_tgt' is the last column\n","ordered_columns = ['time', 'latitude', 'longitude', 'clay_content', 'sand_content', 'silt_content', 'sm_aux', 'location_id', 'sm_tgt']\n","df = df[ordered_columns]\n","june_data = june_data[ordered_columns]\n","\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:39.741701Z","iopub.status.busy":"2023-10-04T11:25:39.741019Z","iopub.status.idle":"2023-10-04T11:25:39.758493Z","shell.execute_reply":"2023-10-04T11:25:39.757102Z","shell.execute_reply.started":"2023-10-04T11:25:39.741659Z"},"trusted":true},"outputs":[],"source":["june_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["<p style=\"color: #34495e; font-size: 18px;\"> One common method to create input sequences for LSTM is the \"sliding window\" approach. For a given time step of n, you'd use the values from t-1, t-2, ... t-n to predict t. Then, you slide the window one step forward and use t, t-1, ... t-(n-1) to predict t+1, and so on.</p>\n","\n","<div style=\"text-align:center;\">\n","    <img src=\"https://github.com/sraocodes/images/blob/main/sequencing.jpg?raw=true\" alt=\"Illustration\" style=\"width:400px; border: 1px solid #e67e22; padding: 5px; border-radius: 8px;\">\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"data_missing\"></a>\n","<h2 style=\"color: #e67e22; border-bottom: 2px solid #3498db; padding-bottom: 10px;\">Handling Incomplete Sequences in Time-Series Forecasting</h2>\n","\n","<div style=\"text-align:center;\">\n","    <img src=\"https://github.com/sraocodes/images/blob/main/discard.jpg?raw=true\" alt=\"Illustration\" style=\"width:700px; border: 1px solid #e67e22; padding: 5px; border-radius: 8px;\">\n","</div>\n","\n","<h4 style=\"color: #3498db;\">The Context:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>In LSTM forecasting, the consistency and completeness of sequences are pivotal. Incomplete sequences can lead to inaccurate training and misleading predictions.</li>\n","</ul>\n","\n","<h4 style=\"color: #3498db;\">Identifying Incomplete Sequences:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>Analyze the dataset to pinpoint any sequences (e.g., locations) with inadequate data. For instance, for monthly data forecasting with a 15-day sequence length, any location with fewer than 15 days of data for a given month might be deemed incomplete and should either be padded or removed.</li>\n","</ul>\n","\n","<h4 style=\"color: #3498db;\">Deciding on Sequence Length:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>The length of the sequence is fundamental in LSTM-based forecasting. A longer sequence can capture more patterns but needs more data. Conversely, a shorter sequence might miss long-term patterns but is more flexible with datasets having sporadic missing values.</li>\n","</ul>\n","\n","<h4 style=\"color: #3498db;\">Filtering Out Incomplete Sequences:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>After determining an appropriate sequence length, filter out sequences that don't meet this criterion. This ensures the LSTM model is fed with consistent input.</li>\n","</ul>\n","\n","<h4 style=\"color: #3498db;\">Rationale:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>LSTMs rely on consistent sequence lengths to discern and learn time-series data patterns. Inputting incomplete sequences can disrupt their learning capability, leading to suboptimal performance. </li>\n","</ul>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:39.75997Z","iopub.status.busy":"2023-10-04T11:25:39.759679Z","iopub.status.idle":"2023-10-04T11:25:39.77565Z","shell.execute_reply":"2023-10-04T11:25:39.774718Z","shell.execute_reply.started":"2023-10-04T11:25:39.759947Z"},"trusted":true},"outputs":[],"source":["# Calculate the number of data points for each location in june_data\n","data_points_per_location = june_data.groupby('location_id').size()\n","\n","# Identify locations with less than 15 days of data\n","locations_to_exclude = data_points_per_location[data_points_per_location < 15].index\n","\n","# Filter out these locations from june_data\n","june_data = june_data[~june_data['location_id'].isin(locations_to_exclude)]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:39.777403Z","iopub.status.busy":"2023-10-04T11:25:39.776961Z","iopub.status.idle":"2023-10-04T11:25:41.887608Z","shell.execute_reply":"2023-10-04T11:25:41.886604Z","shell.execute_reply.started":"2023-10-04T11:25:39.777377Z"},"trusted":true},"outputs":[],"source":["def create_sequences(data, seq_length):\n","    \"\"\"\n","    Create input-output sequence pairs from the provided dataframe.\n","    \"\"\"\n","    X, Y = [], []\n","\n","    for location, group in data.groupby('location_id'):\n","        # Extract relevant features from the group\n","        features = group[features_to_normalize].drop(columns='sm_tgt').values\n","        targets = group['sm_tgt'].values\n","        \n","        # Create sequences\n","        for i in range(len(features) - seq_length):\n","            X.append(features[i:i+seq_length])\n","            Y.append(targets[i+seq_length])\n","            \n","    return X, Y\n","\n","# Define the sequence length (30 days)\n","seq_length = 15\n","\n","# Create sequences for training data\n","X, Y = create_sequences(df, seq_length)\n","\n","# Convert lists to numpy arrays for easier handling later\n","X = np.array(X)\n","Y = np.array(Y)\n","\n","X.shape, Y.shape"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"intro_notebook\"></a>\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"lstm_model\"></a>\n","<h2 style=\"color: #e67e22; border-bottom: 2px solid #3498db; padding-bottom: 10px;\">LSTM Model</h2>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:25:41.889388Z","iopub.status.busy":"2023-10-04T11:25:41.888979Z","iopub.status.idle":"2023-10-04T11:35:02.696582Z","shell.execute_reply":"2023-10-04T11:35:02.695368Z","shell.execute_reply.started":"2023-10-04T11:25:41.889351Z"},"trusted":true},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import LSTM, BatchNormalization, Dropout, Dense\n","from keras.regularizers import l2\n","\n","model = Sequential()\n","model.add(LSTM(75, activation='relu', input_shape=(X.shape[1], X.shape[2]), kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), return_sequences=True))\n","model.add(LSTM(75, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.4))\n","# Dense output layer\n","model.add(Dense(1))\n","model.compile(optimizer='adam', loss='mse')\n","\n","# Define early stopping callback\n","early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n","\n","# Train the model with early stopping\n","history = model.fit(X, Y, epochs=10, batch_size=128, validation_split=0.2, verbose=1, callbacks=[early_stop])\n","\n","# Plot the training and validation loss\n","\n","plt.figure(figsize=(12, 6))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('LSTM Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Mean Squared Error (MSE)')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:35:02.69816Z","iopub.status.busy":"2023-10-04T11:35:02.697867Z","iopub.status.idle":"2023-10-04T11:35:04.06658Z","shell.execute_reply":"2023-10-04T11:35:04.065403Z","shell.execute_reply.started":"2023-10-04T11:35:02.698134Z"},"trusted":true},"outputs":[],"source":["X_june, Y_june_true = create_sequences(june_data, seq_length)\n","X_june = np.array(X_june);\n","Y_june_true = np.array(Y_june_true);\n","model.compile(optimizer='adam', loss='mse');\n","X_june.shape,Y_june_true.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:35:04.068854Z","iopub.status.busy":"2023-10-04T11:35:04.067977Z","iopub.status.idle":"2023-10-04T11:35:05.930224Z","shell.execute_reply":"2023-10-04T11:35:05.929228Z","shell.execute_reply.started":"2023-10-04T11:35:04.06881Z"},"trusted":true},"outputs":[],"source":["\n","predictions = model.predict(X_june,batch_size=128)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:35:05.93198Z","iopub.status.busy":"2023-10-04T11:35:05.931713Z","iopub.status.idle":"2023-10-04T11:35:05.937944Z","shell.execute_reply":"2023-10-04T11:35:05.937166Z","shell.execute_reply.started":"2023-10-04T11:35:05.931957Z"},"trusted":true},"outputs":[],"source":["def reverse_scaling(data, scaler):\n","    \"\"\"\n","    Reverse the scaling effect on data.\n","    \"\"\"\n","    # Convert data to a 2D array if it's 1D\n","    if len(data.shape) == 1:\n","        data = data.reshape(-1, 1)\n","    \n","    dummy = np.zeros((len(data), len(features_to_normalize)))\n","    \n","    # Set the last column of the dummy array to your data\n","    dummy[:, -1] = data.ravel()\n","    \n","    # Use inverse_transform to reverse the scaling\n","    unscaled = scaler.inverse_transform(dummy)\n","    \n","    # Return the last column (our actual unscaled data)\n","    return unscaled[:, -1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:35:05.93981Z","iopub.status.busy":"2023-10-04T11:35:05.938837Z","iopub.status.idle":"2023-10-04T11:35:05.951846Z","shell.execute_reply":"2023-10-04T11:35:05.950886Z","shell.execute_reply.started":"2023-10-04T11:35:05.939781Z"},"trusted":true},"outputs":[],"source":["# Reverse scaling for Y_june_true and predictions\n","Y_june_true_unscaled = reverse_scaling(Y_june_true, scaler)\n","predictions_unscaled = reverse_scaling(predictions, scaler)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:35:05.95375Z","iopub.status.busy":"2023-10-04T11:35:05.952851Z","iopub.status.idle":"2023-10-04T11:35:06.694696Z","shell.execute_reply":"2023-10-04T11:35:06.693541Z","shell.execute_reply.started":"2023-10-04T11:35:05.953722Z"},"trusted":true},"outputs":[],"source":["# Ensure both arrays are 1-dimensional\n","Y_june_true_unscaled = Y_june_true_unscaled.ravel()\n","predictions_unscaled = predictions_unscaled.ravel()\n","\n","# Create a DataFrame for plotting\n","df_plot = pd.DataFrame({\n","    'Actual Values': Y_june_true_unscaled,\n","    'Predicted Values': predictions_unscaled\n","})\n","\n","# Set Seaborn style\n","sns.set_style(\"whitegrid\")\n","\n","# Create a line plot\n","plt.figure(figsize=(12, 6))\n","sns.lineplot(data=df_plot)\n","plt.title('Comparison of Actual vs Predicted Soil Moisture for June')\n","plt.ylabel('Soil Moisture')\n","plt.xlabel('Days in June')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:35:06.696555Z","iopub.status.busy":"2023-10-04T11:35:06.696138Z","iopub.status.idle":"2023-10-04T11:35:06.703649Z","shell.execute_reply":"2023-10-04T11:35:06.702564Z","shell.execute_reply.started":"2023-10-04T11:35:06.696519Z"},"trusted":true},"outputs":[],"source":["# Calculate MAE\n","mae = np.mean(np.abs(Y_june_true_unscaled - predictions_unscaled))\n","print(f\"Mean Absolute Error for June Predictions: {mae}\")"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"conclu\"></a>\n","<h2 style=\"color: #e67e22; border-bottom: 2px solid #3498db; padding-bottom: 10px;\">Conclusion: Taking Baby Steps with LSTM</h2>\n","\n","<h4 style=\"color: #3498db;\">What We Achieved:</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>We built an LSTM model and got an error score of 0.06 to 0.07. This means our model is doing something right!</li>\n","    <li>Our model seems to \"get\" the bigger picture of soil moisture data trend, even if it misses some small details. There is definetly room to improve it by incorporating L1 or L2 regularization, playing with batch size or epochs etc.</li>\n","</ul>\n","\n","<h4 style=\"color: #3498db;\">What's Next?</h4>\n","<ul style=\"color: #34495e; font-size: 16px;\">\n","    <li>But remember, our main goal was to show how LSTMs can work even when some data is missing. And we did that!</li>\n","</ul>\n","\n","\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3797521,"sourceId":6575557,"sourceType":"datasetVersion"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
